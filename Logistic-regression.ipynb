{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "717282d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, recall_score, f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af830a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./data/X_train.csv')\n",
    "X_test = pd.read_csv('./data/X_test.csv')\n",
    "y_train = pd.read_csv('./data/y_train.csv')\n",
    "y_test = pd.read_csv('./data/y_test.csv')\n",
    "X_val = pd.read_csv('./data/X_val.csv')\n",
    "y_val = pd.read_csv('./data/y_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c25d8591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        worse tea fresh green tea indeed green tea tim...\n",
       "1        ive tasted best real things wonderful dreadful...\n",
       "2        love taste good ginger snap cookie saw offered...\n",
       "3        absolutely love coachs oatmeal hated oatmeal t...\n",
       "4        normally dont go instant coffees delicious ins...\n",
       "                               ...                        \n",
       "96058    ive loved graham crackers since kid many brand...\n",
       "96059    decided give try since kcup coffee prices goin...\n",
       "96060    excellent coffee either brewed hot ice drink l...\n",
       "96061    reading useful negative review times comment t...\n",
       "96062    excited high protein pretzels opened tasted ta...\n",
       "Name: text, Length: 96063, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.iloc[:,0]\n",
    "X_test = X_test.iloc[:,0]\n",
    "y_train = y_train.iloc[:,0]\n",
    "y_test = y_test.iloc[:,0]\n",
    "X_val = X_val.iloc[:,0]\n",
    "y_val = y_val.iloc[:,0]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89705842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=[X_train, y_train], index=[\"text\", \"label\"]).T\n",
    "df = df.append(pd.DataFrame(data=[X_val, y_val], index=[\"text\", \"label\"]).T)\n",
    "df = df.append(pd.DataFrame(data=[X_test, y_test], index=[\"text\", \"label\"]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac74ba",
   "metadata": {},
   "source": [
    "### One-Hot encoding (CountVectorizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a225c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(df['text'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(X_train)\n",
    "xvalid_count =  count_vect.transform(X_val)\n",
    "xtest_count =  count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f132608",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbcaecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=10000)\n",
    "tfidf_vect.fit(df['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
    "xvalid_tfidf =  tfidf_vect.transform(X_val)\n",
    "xtest_tfidf =  tfidf_vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90843f13",
   "metadata": {},
   "source": [
    "# Model with Countvect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bef61e",
   "metadata": {},
   "source": [
    "from sklearn import preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "model1 = naive_bayes.MultinomialNB()\n",
    "model1.fit(xtrain_count,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6675799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "c:\\users\\iambo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(verbose=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression(verbose=True)\n",
    "model1.fit(xtrain_count,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cd1aab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\iambo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\users\\iambo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\users\\iambo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\users\\iambo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\users\\iambo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9342701 , 0.94097439, 0.93488445, 0.93425984, 0.92816989])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, xvalid_count, y_val, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38bc703f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93 accuracy with a standard deviation of 0.00\n"
     ]
    }
   ],
   "source": [
    " print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49d2d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model1.predict(xtest_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82415ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4421   870]\n",
      " [  548 26183]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5661f064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86      5291\n",
      "           1       0.97      0.98      0.97     26731\n",
      "\n",
      "    accuracy                           0.96     32022\n",
      "   macro avg       0.93      0.91      0.92     32022\n",
      "weighted avg       0.95      0.96      0.96     32022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98999092",
   "metadata": {},
   "source": [
    "# Model with Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4965a511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2= LogisticRegression()\n",
    "model2.fit(xtrain_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa22f291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91209992, 0.9156777 , 0.91427233, 0.91552155, 0.90490319])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, xvalid_tfidf, y_val, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daaf9e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91 accuracy with a standard deviation of 0.00\n"
     ]
    }
   ],
   "source": [
    " print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bd7558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model2.predict(xtest_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90b4c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3693  1598]\n",
      " [  450 26281]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "866079c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.70      0.78      5291\n",
      "           1       0.94      0.98      0.96     26731\n",
      "\n",
      "    accuracy                           0.94     32022\n",
      "   macro avg       0.92      0.84      0.87     32022\n",
      "weighted avg       0.93      0.94      0.93     32022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
