{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GB-word2vec-prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljy9pHwuDBTN",
        "outputId": "5ef03ad9-f158-4fac-c03d-383713249d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn import decomposition, ensemble\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import balanced_accuracy_score, recall_score, f1_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import time"
      ],
      "metadata": {
        "id": "MtNDT7RoD2kg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re    # for regular expressions \n",
        "import nltk  # for text manipulation \n",
        "import string \n",
        "import warnings \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt  \n",
        "import gensim\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 200) \n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "dDPTqPQrD5dp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/X_train.csv')\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/X_test.csv')\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/y_train.csv')\n",
        "y_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/y_test.csv')\n",
        "X_val = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/X_val.csv')\n",
        "y_val = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/y_val.csv')"
      ],
      "metadata": {
        "id": "JZxFPYlYD7xY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.iloc[:,0]\n",
        "X_test = X_test.iloc[:,0]\n",
        "y_train = y_train.iloc[:,0]\n",
        "y_test = y_test.iloc[:,0]\n",
        "X_val = X_val.iloc[:,0]\n",
        "y_val = y_val.iloc[:,0]\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxe-fjZbHiFu",
        "outputId": "4c03ea60-3692-4b1d-ef05-19ef413a1a6b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        worse tea fresh green tea indeed green tea time produced poor storing condition sealed enviroment exposed extensively air make tea lost flavor dont know old tea experience least 35 years old loose...\n",
              "1        ive tasted best real things wonderful dreadfully high fat carbs calories includes dressings dips sauces yes ive added goes salad oil fat content calories soar expect fatfree substitute anything cl...\n",
              "2        love taste good ginger snap cookie saw offered jumped thinking easy review would wellas taste great true ginger snap flavor opened bag smell made mouth water cookie extremely hard really hard time...\n",
              "3        absolutely love coachs oatmeal hated oatmeal till tasted coach oatmeal first 2 bags bought costconow costco doesnt carry anymoreso went line find coach oatmeal amazon carry happy found themi oatme...\n",
              "4        normally dont go instant coffees delicious instructions suggest 4 teaspoons 68oz hot water used 5 teaspoons 12oz water dollop silk soy creamer made delicious peppermint mocha low fat high taste st...\n",
              "                                                                                                          ...                                                                                                   \n",
              "96058    ive loved graham crackers since kid many brands arent good used enter back nature golden honey oat grahams crispy hearty whole grain nutty taste great coffee tea bit crispier elf name brand graham...\n",
              "96059    decided give try since kcup coffee prices going brewed large mug tumbler size keurig b70 isnt dark peets ekobrew adapter might peets darker roast stronger green mtn colombian maybe dark magicbr br...\n",
              "96060        excellent coffee either brewed hot ice drink lot ice coffee love dark magic great taste boldness never gives heartburn fits morning coffee time evenings patio get coffee like bold excellent brews\n",
              "96061    reading useful negative review times comment things knowbr br heres knowbr br start supplementing formula around 8 months wifes breast milk supply started decrease daughter took formula without pr...\n",
              "96062    excited high protein pretzels opened tasted tasted burned inspected rest bags package look dark brown dont know received bad batch also ordered spelt pretzels vitacost lower priced like price sudd...\n",
              "Name: text, Length: 96063, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data=[X_train, y_train], index=[\"text\", \"label\"]).T\n",
        "df = df.append(pd.DataFrame(data=[X_val, y_val], index=[\"text\", \"label\"]).T)\n",
        "df = df.append(pd.DataFrame(data=[X_test, y_test], index=[\"text\", \"label\"]).T)"
      ],
      "metadata": {
        "id": "xlRUsDutIC0z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_w2v = gensim.models.Word2Vec.load(\"/content/drive/MyDrive/Colab Notebooks/word2vec.model\")"
      ],
      "metadata": {
        "id": "XMtzRIPjILZX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_w2v.wv.most_similar(positive=\"tea\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzuwnTRhIS6l",
        "outputId": "0db22e22-1632-460f-b3ca-5df376ea2edf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('teas', 0.7136606574058533),\n",
              " ('chai', 0.604446291923523),\n",
              " ('hrefhttpwwwamazoncomgpproductb0012bzghsstash', 0.5814846158027649),\n",
              " ('higgins', 0.5766370892524719),\n",
              " ('hrefhttpwwwamazoncomgpproductb000f4h5qitwinings', 0.5731595158576965),\n",
              " ('lipton', 0.5673545598983765),\n",
              " ('rejuvination', 0.5584450364112854),\n",
              " ('herbal', 0.5564500689506531),\n",
              " ('burke', 0.556394100189209),\n",
              " ('asinb000cqe3nm', 0.5519647598266602)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_w2v.wv.most_similar(positive=\"terrible\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fHmHhObZ6Eo",
        "outputId": "b24c85f4-e3f4-43bd-a84e-2960465d3a20"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('piecebatchbag', 0.5067934393882751),\n",
              " ('horrible', 0.5022017359733582),\n",
              " ('bad', 0.4886583387851715),\n",
              " ('corpoate', 0.46941494941711426),\n",
              " ('facialno', 0.4491904377937317),\n",
              " ('hypomag', 0.4458191692829132),\n",
              " ('instaed', 0.4442039132118225),\n",
              " ('immitation', 0.443316251039505),\n",
              " ('sucralosejust', 0.4379229247570038),\n",
              " ('poor', 0.4314398169517517)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[0,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQVosKqpjy1c",
        "outputId": "11dd72bb-6bb5-456a-f494-bd6b0388f815"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     worse tea fresh green tea indeed green tea time produced poor storing condition sealed enviroment exposed extensively air make tea lost flavor dont know old tea experience least 35 years old loose...\n",
              "label                                                                                                                                                                                                          0\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_reviews = X_train.apply(lambda x: x.split()) # tokenizing "
      ],
      "metadata": {
        "id": "2AAs9VUBirnh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_reviews.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxUBRRhMrwzQ",
        "outputId": "cb84f20b-a2b6-4b38-8ac1-549fd7231da9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96063,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_vector(tokens, size):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += model_w2v[word].reshape((1, size))\n",
        "            count += 1.\n",
        "        except KeyError:  # handling the case where the token is not in vocabulary\n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ],
      "metadata": {
        "id": "cSrPb4Lwfjbn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordvec_arrays = np.zeros((len(tokenized_reviews), 200)) \n"
      ],
      "metadata": {
        "id": "WPwzcrZ8ilTD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(tokenized_reviews)):\n",
        "    wordvec_arrays[i,:] = word_vector(tokenized_reviews[i], 200)"
      ],
      "metadata": {
        "id": "Ikvwl0MFjW6n"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordvec_arrays.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9jdMiqFr4aB",
        "outputId": "f45a07af-13f4-4ba4-fd6d-405461e815e0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96063, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
        "wordvec_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PngQSQSBoEvs",
        "outputId": "1b68614b-cd7a-492c-f6b1-f8f3c9b0f9ca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96063, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "model3 = GradientBoostingClassifier(verbose=1)\n",
        "model3.fit(wordvec_df,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkurGbgRTSQ9",
        "outputId": "e57fcd20-f8c9-4382-91c0-c18a136beefe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.8763           13.39m\n",
            "         2           0.8608           13.26m\n",
            "         3           0.8478           13.12m\n",
            "         4           0.8362           13.10m\n",
            "         5           0.8248           12.92m\n",
            "         6           0.8141           12.76m\n",
            "         7           0.8029           12.58m\n",
            "         8           0.7923           12.42m\n",
            "         9           0.7836           12.37m\n",
            "        10           0.7750           12.22m\n",
            "        20           0.7016           10.80m\n",
            "        30           0.6512            9.42m\n",
            "        40           0.6146            8.09m\n",
            "        50           0.5843            6.73m\n",
            "        60           0.5602            5.38m\n",
            "        70           0.5396            4.03m\n",
            "        80           0.5228            2.69m\n",
            "        90           0.5072            1.34m\n",
            "       100           0.4942            0.00s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_reviews_val = X_val.apply(lambda x: x.split()) # tokenizing \n",
        "wordvec_arrays_val = np.zeros((len(tokenized_reviews_val), 200)) \n",
        "for i in range(len(tokenized_reviews_val)):\n",
        "    wordvec_arrays_val[i,:] = word_vector(tokenized_reviews_val[i], 200)\n",
        "wordvec_df_val = pd.DataFrame(wordvec_arrays_val)\n",
        "wordvec_df_val.shape    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuJp-S1ez39G",
        "outputId": "10ac5dbf-a7b2-4f4f-ec24-ab4c4c853087"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32021, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(model3, wordvec_df_val, y_val, cv=5)\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i37AS05z1qm",
        "outputId": "bd8ade39-f85f-4205-8d8d-bb602a7df766"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.8770            3.39m\n",
            "         2           0.8592            3.33m\n",
            "         3           0.8449            3.30m\n",
            "         4           0.8313            3.25m\n",
            "         5           0.8205            3.22m\n",
            "         6           0.8087            3.17m\n",
            "         7           0.7973            3.14m\n",
            "         8           0.7871            3.10m\n",
            "         9           0.7775            3.06m\n",
            "        10           0.7690            3.03m\n",
            "        20           0.6963            2.67m\n",
            "        30           0.6421            2.33m\n",
            "        40           0.6026            2.00m\n",
            "        50           0.5704            1.66m\n",
            "        60           0.5431            1.33m\n",
            "        70           0.5203           59.89s\n",
            "        80           0.5005           39.96s\n",
            "        90           0.4833           20.00s\n",
            "       100           0.4684            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.8780            3.28m\n",
            "         2           0.8619            3.26m\n",
            "         3           0.8476            3.23m\n",
            "         4           0.8350            3.19m\n",
            "         5           0.8219            3.16m\n",
            "         6           0.8107            3.12m\n",
            "         7           0.7994            3.09m\n",
            "         8           0.7888            3.06m\n",
            "         9           0.7788            3.02m\n",
            "        10           0.7691            2.99m\n",
            "        20           0.6954            2.65m\n",
            "        30           0.6433            2.32m\n",
            "        40           0.6030            1.99m\n",
            "        50           0.5719            1.66m\n",
            "        60           0.5456            1.33m\n",
            "        70           0.5228           59.88s\n",
            "        80           0.5041           39.95s\n",
            "        90           0.4872           19.98s\n",
            "       100           0.4723            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.8777            3.33m\n",
            "         2           0.8619            3.28m\n",
            "         3           0.8484            3.26m\n",
            "         4           0.8348            3.22m\n",
            "         5           0.8227            3.18m\n",
            "         6           0.8105            3.15m\n",
            "         7           0.7991            3.12m\n",
            "         8           0.7883            3.08m\n",
            "         9           0.7788            3.04m\n",
            "        10           0.7695            3.01m\n",
            "        20           0.6934            2.66m\n",
            "        30           0.6405            2.33m\n",
            "        40           0.6005            1.99m\n",
            "        50           0.5683            1.66m\n",
            "        60           0.5426            1.33m\n",
            "        70           0.5205           59.83s\n",
            "        80           0.5018           39.88s\n",
            "        90           0.4845           19.95s\n",
            "       100           0.4694            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.8777            3.31m\n",
            "         2           0.8615            3.27m\n",
            "         3           0.8479            3.23m\n",
            "         4           0.8345            3.19m\n",
            "         5           0.8221            3.16m\n",
            "         6           0.8101            3.12m\n",
            "         7           0.7993            3.08m\n",
            "         8           0.7887            3.05m\n",
            "         9           0.7790            3.01m\n",
            "        10           0.7694            2.98m\n",
            "        20           0.6945            2.65m\n",
            "        30           0.6410            2.32m\n",
            "        40           0.6009            1.98m\n",
            "        50           0.5682            1.66m\n",
            "        60           0.5427            1.33m\n",
            "        70           0.5200           59.67s\n",
            "        80           0.5007           39.77s\n",
            "        90           0.4838           19.90s\n",
            "       100           0.4687            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.8769            3.29m\n",
            "         2           0.8610            3.24m\n",
            "         3           0.8450            3.22m\n",
            "         4           0.8314            3.19m\n",
            "         5           0.8197            3.16m\n",
            "         6           0.8076            3.13m\n",
            "         7           0.7959            3.09m\n",
            "         8           0.7856            3.05m\n",
            "         9           0.7755            3.02m\n",
            "        10           0.7663            2.98m\n",
            "        20           0.6917            2.64m\n",
            "        30           0.6376            2.31m\n",
            "        40           0.5970            1.98m\n",
            "        50           0.5637            1.65m\n",
            "        60           0.5362            1.32m\n",
            "        70           0.5139           59.60s\n",
            "        80           0.4939           39.76s\n",
            "        90           0.4770           19.89s\n",
            "       100           0.4626            0.00s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.88961749, 0.89506558, 0.89225484, 0.89241099, 0.88897564])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_reviews_test = X_test.apply(lambda x: x.split()) # tokenizing "
      ],
      "metadata": {
        "id": "S1bN7OdZtHBN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordvec_arrays_test = np.zeros((len(tokenized_reviews_test), 200)) \n",
        "for i in range(len(tokenized_reviews_test)):\n",
        "    wordvec_arrays_test[i,:] = word_vector(tokenized_reviews_test[i], 200)"
      ],
      "metadata": {
        "id": "ibYbjNXatMRf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordvec_df_test = pd.DataFrame(wordvec_arrays_test)\n",
        "wordvec_df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhVadQAvtT1D",
        "outputId": "b2549d60-0039-4e5a-a843-2a201757e531"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32022, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model3.predict(wordvec_df_test)"
      ],
      "metadata": {
        "id": "Qa7zeRQftBgg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv4In-z1tdpY",
        "outputId": "59756a4f-d689-49fc-dd6e-8b64765846c4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2322  2969]\n",
            " [  375 26356]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcMna-iCtjCT",
        "outputId": "30a581e3-5d4d-438e-8f2f-6b6fca504462"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.44      0.58      5291\n",
            "           1       0.90      0.99      0.94     26731\n",
            "\n",
            "    accuracy                           0.90     32022\n",
            "   macro avg       0.88      0.71      0.76     32022\n",
            "weighted avg       0.89      0.90      0.88     32022\n",
            "\n"
          ]
        }
      ]
    }
  ]
}